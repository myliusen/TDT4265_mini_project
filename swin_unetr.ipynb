{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary imports\n",
    "\n",
    "This was my top scoring model, inspired by https://github.com/Project-MONAI/tutorials/blob/main/3d_segmentation/swin_unetr_btcv_segmentation_3d.ipynb, then augmented using literature and asking Gemini to implement some changes to the configuration and transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from monai.losses import DiceCELoss # Use combined loss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNet\n",
    "from monai.data import Dataset, DataLoader, decollate_batch\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, Spacingd, CropForegroundd,\n",
    "    Resized, DivisiblePadd, ToTensord, RandFlipd, RandAffined, RandScaleIntensityd,\n",
    "    RandShiftIntensityd, ScaleIntensityRangePercentilesd, EnsureType, AsDiscrete,\n",
    "    RandGaussianNoised, RandAdjustContrastd\n",
    ")\n",
    "from monai.utils import set_determinism, first\n",
    "from monai.networks.nets import SwinUNETR\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.optim import AdamW \n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "# import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from monai.inferers import sliding_window_inference # Keep this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration and file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "set_determinism(seed=SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "data_dir = '/datasets/tdt4265/mic/open/HNTS-MRG'\n",
    "CHECKPOINT_DIR = \"./checkpoints_swin_v2\"\n",
    "BEST_MODEL_PATH = f\"{CHECKPOINT_DIR}/best_metric_model_swin_v2.pth\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Data Loading ---\n",
    "train_images = sorted([f for f in glob(os.path.join(data_dir, 'train', '*', 'preRT', '*.nii.gz')) if '_mask' not in f])\n",
    "train_labels = sorted([f for f in glob(os.path.join(data_dir, 'train', '*', 'preRT', '*.nii.gz')) if '_T2' not in f])\n",
    "val_images = sorted([f for f in glob(os.path.join(data_dir, 'test', '*', 'preRT', '*.nii.gz')) if '_mask' not in f])\n",
    "val_labels = sorted([f for f in glob(os.path.join(data_dir, 'test', '*', 'preRT', '*.nii.gz')) if '_T2' not in f])\n",
    "\n",
    "train_files = [{'image': image_name, 'label': label_name} for image_name, label_name in zip(train_images, train_labels)]\n",
    "val_files = [{'image': image_name, 'label': label_name} for image_name, label_name in zip(val_images, val_labels)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the dimensions\n",
    "TARGET_SPACING = (1.5, 1.5, 2.0)\n",
    "TARGET_SIZE = (160, 160, 96)\n",
    "PAD_K = 16 \n",
    "\n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=['image', 'label']),\n",
    "    EnsureChannelFirstd(keys=['image', 'label']),\n",
    "    Spacingd(keys=['image', 'label'], pixdim=TARGET_SPACING, mode=('bilinear', 'nearest')),\n",
    "    # *** RE-ENABLED CropForegroundd *** (Crucial)\n",
    "    CropForegroundd(keys=['image', 'label'], source_key='image', margin=10),\n",
    "    ScaleIntensityRangePercentilesd(keys='image', lower=0.5, upper=99.5,\n",
    "                               b_min=0.0, b_max=1.0, clip=True),\n",
    "\n",
    "    # Augmentation:\n",
    "    RandFlipd(keys=['image','label'], spatial_axis=0, prob=0.5), \n",
    "    RandFlipd(keys=['image','label'], spatial_axis=1, prob=0.5),\n",
    "    RandFlipd(keys=['image','label'], spatial_axis=2, prob=0.5), \n",
    "    RandAffined(\n",
    "        keys=['image','label'],\n",
    "        rotate_range=(0.1, 0.1, 0.1), \n",
    "        scale_range=(0.2, 0.2, 0.2), \n",
    "        mode=('bilinear','nearest'),\n",
    "        prob=0.3 \n",
    "    ),\n",
    "    RandGaussianNoised(keys='image', prob=0.2, mean=0.0, std=0.05),\n",
    "    RandAdjustContrastd(keys='image', prob=0.2, gamma=(0.7, 1.3)),\n",
    "    RandScaleIntensityd(keys='image', factors=0.2, prob=0.2), \n",
    "    RandShiftIntensityd(keys='image', offsets=0.15, prob=0.3),\n",
    "\n",
    "    Resized(keys=['image','label'], spatial_size=TARGET_SIZE, mode=('bilinear', 'nearest')),\n",
    "    DivisiblePadd(keys=['image','label'], k=PAD_K, mode='constant', constant_values=0),\n",
    "    ToTensord(keys=['image','label'])\n",
    "])\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=['image', 'label']),\n",
    "        EnsureChannelFirstd(keys=['image', 'label']),\n",
    "        Spacingd(keys=['image', 'label'], pixdim=TARGET_SPACING, mode=('bilinear', 'nearest')),\n",
    "        CropForegroundd(keys=['image', 'label'], source_key='image', margin=10),\n",
    "        ScaleIntensityRangePercentilesd(keys='image', lower=0.5, upper=99.5,\n",
    "                               b_min=0.0, b_max=1.0, clip=True),\n",
    "        Resized(keys=['image', 'label'], spatial_size=TARGET_SIZE, mode=('bilinear', 'nearest')),\n",
    "        DivisiblePadd(keys=['image', 'label'], k=PAD_K, mode='constant', constant_values=0),\n",
    "        ToTensord(keys=['image', 'label'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = Dataset(data=train_files, transform=train_transforms)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=1, shuffle=True, num_workers=4)\n",
    "\n",
    "val_dataset = Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SwinUNETR(\n",
    "    img_size=TARGET_SIZE,\n",
    "    in_channels=1,\n",
    "    out_channels=3,       # Background, Class1, Class2\n",
    "    feature_size=48,      # Standard feature size\n",
    "    dropout_path_rate=0.2, # Keep this for now, can tune later\n",
    "    use_checkpoint=True,   # Use gradient checkpointing to save memory if needed\n",
    ").to(device)\n",
    "\n",
    "ckpt = torch.load(\"model_swinvit.pt\", map_location=device)\n",
    "# Check if the checkpoint has a 'state_dict' key or is the state_dict directly\n",
    "if 'state_dict' in ckpt:\n",
    "    state_dict = ckpt['state_dict']\n",
    "else:\n",
    "    state_dict = ckpt\n",
    "\n",
    "print(\"Loaded pretrained Swin UNETR weights!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 300\n",
    "val_interval = 5\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "lr_values = []\n",
    "\n",
    "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=3)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=3)])\n",
    "loss_function = DiceCELoss(to_onehot_y=True, softmax=True, include_background=True)\n",
    "\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean_batch\", get_not_nans=True) # Focus metric on foreground\n",
    "dice_metric_bg = DiceMetric(include_background=True, reduction=\"mean_batch\", get_not_nans=True) # Separate metric for full reporting\n",
    "\n",
    "# Optimizer\n",
    "initial_lr = 1e-4\n",
    "optimizer = AdamW(model.parameters(), lr=initial_lr, weight_decay=1e-5) # Start with same WD, tune if needed\n",
    "\n",
    "# Warmup as recommended by UDL\n",
    "warmup_epochs = 10\n",
    "\n",
    "# Scheduler\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=max_epochs - warmup_epochs, eta_min=1e-6) \n",
    "# See later that MONAI has builtin WarmupCosineSchedule, maybe could've used that instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_validation(model, val_loader, post_pred, post_label, dice_metric, dice_metric_bg, device, epoch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for val_data in val_loader:\n",
    "            images = val_data[\"image\"].to(device)\n",
    "            labels = val_data[\"label\"].to(device)\n",
    "\n",
    "            # *** Use overlap in sliding window inference ***\n",
    "            outputs = sliding_window_inference(\n",
    "                images, roi_size=TARGET_SIZE, sw_batch_size=2, predictor=model, overlap=0.5\n",
    "            )\n",
    "\n",
    "            # post‚Äêprocess into lists of tensors\n",
    "            y_pred = [post_pred(x) for x in decollate_batch(outputs)]\n",
    "            y_true = [post_label(x) for x in decollate_batch(labels)]\n",
    "\n",
    "            # Calculate metrics\n",
    "            dice_metric(y_pred=y_pred, y=y_true)\n",
    "            dice_metric_bg(y_pred=y_pred, y=y_true)\n",
    "\n",
    "    # Aggregate metrics\n",
    "    metric_foreground, _ = dice_metric.aggregate()\n",
    "    metric_all, _ = dice_metric_bg.aggregate()\n",
    "    dice_metric.reset()\n",
    "    dice_metric_bg.reset()\n",
    "\n",
    "    # Extract per-class Dice (assuming metric_all gives [bg, c1, c2])\n",
    "    # Handle potential case where a class is not present in any validation sample\n",
    "    dice_bg = metric_all[0].item() if len(metric_all)>0 else 0\n",
    "    dice_cls1 = metric_all[1].item() if len(metric_all)>1 else 0\n",
    "    dice_cls2 = metric_all[2].item() if len(metric_all)>2 else 0\n",
    "\n",
    "    # Average foreground Dice\n",
    "    avg_dice_foregrounds = metric_foreground.mean().item()\n",
    "\n",
    "    # Store detailed metrics\n",
    "    metric_values.append((\n",
    "        epoch + 1,\n",
    "        dice_bg,\n",
    "        dice_cls1,\n",
    "        dice_cls2,\n",
    "        avg_dice_foregrounds # This is the primary metric for comparison now\n",
    "    ))\n",
    "\n",
    "    print(f\"Dice(background): {dice_bg:.4f}, Dice(class1): {dice_cls1:.4f}, \"\n",
    "          f\"Dice(class2): {dice_cls2:.4f}, Avg(foregrounds): {avg_dice_foregrounds:.4f}\")\n",
    "\n",
    "    return avg_dice_foregrounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_patience = 25 \n",
    "early_stopping_counter = 0\n",
    "\n",
    "print(f\"Starting training for {max_epochs} epochs...\")\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(f\"\\n--- Epoch {epoch+1}/{max_epochs} ---\")\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    # Manual Warmup Phase\n",
    "    if epoch < warmup_epochs:\n",
    "        # Simple linear warmup\n",
    "        warmup_factor = (epoch + 1) / warmup_epochs\n",
    "        current_lr = initial_lr * warmup_factor\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = current_lr\n",
    "        print(f\"  Warmup: LR set to {current_lr:.6f}\")\n",
    "    elif epoch == warmup_epochs:\n",
    "         print(f\"  Warmup finished. Cosine annealing starts.\")\n",
    "\n",
    "    for step, batch_data in enumerate(train_loader, 1):\n",
    "        images = batch_data[\"image\"].to(device)\n",
    "        labels = batch_data[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        # Optional: Gradient clipping (can help stabilize training)\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if step % 5 == 0: # Print less frequently\n",
    "             print(f\"  step {step:>3}/{len(train_loader):<3}  loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Step the scheduler *after* the optimizer step, only *after* warmup phase\n",
    "    if epoch >= warmup_epochs:\n",
    "         scheduler.step()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    print(f\"  Average Train Loss: {avg_train_loss:.4f}\")\n",
    "    epoch_loss_values.append((epoch+1, avg_train_loss))\n",
    "    lr_values.append((epoch+1, current_lr)) # Log the actual LR used\n",
    "\n",
    "    # --- Validation ---\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        val_metric = run_validation(model, val_loader, post_pred, post_label, dice_metric, dice_metric_bg, device, epoch)\n",
    "        print(f\"  Validation Avg Foreground Dice: {val_metric:.4f}   (best: {best_metric:.4f} at epoch {best_metric_epoch})\")\n",
    "\n",
    "        # Early stopping logic (based on foreground Dice)\n",
    "        if val_metric > best_metric:\n",
    "            best_metric = val_metric\n",
    "            best_metric_epoch = epoch + 1\n",
    "            early_stopping_counter = 0 # Reset counter\n",
    "\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"scheduler_state_dict\": scheduler.state_dict() if scheduler else None, # Save scheduler state\n",
    "                    \"best_metric\": best_metric,\n",
    "                },\n",
    "                BEST_MODEL_PATH,\n",
    "            )\n",
    "            print(f\" best model saved at epoch {best_metric_epoch}!\")\n",
    "\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            print(f\"No improvement. Counter: {early_stopping_counter}/{early_stopping_patience}\")\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered after {early_stopping_patience * val_interval} epochs ({early_stopping_counter} checks) without improvement.\")\n",
    "                break # Stop training\n",
    "\n",
    "print(f\"\\nTraining finished. Best validation foreground Dice: {best_metric:.4f} at epoch {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Unpack the data from the metric collections.\n",
    "# For the dice metrics (validation), each element in metric_values is:\n",
    "# (epoch, dice_bg, dice_cls1, dice_cls2, avg_dice_foregrounds)\n",
    "epochs_dice, dice_bg, dice_cls1, dice_cls2, avg_dice_fg = zip(*metric_values)\n",
    "\n",
    "# For the training loss (average in-sample error), each element in epoch_loss_values is:\n",
    "# (epoch, avg_train_loss)\n",
    "epochs_loss, train_loss = zip(*epoch_loss_values)\n",
    "\n",
    "# Create a figure with two y-axes.\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot Dice scores on the primary y-axis.\n",
    "ax1.plot(epochs_dice, dice_bg, 'b-o', label='Dice (Background)')\n",
    "ax1.plot(epochs_dice, dice_cls1, color='orange', marker='o', linestyle='-', label='Dice (Class 1)')\n",
    "ax1.plot(epochs_dice, dice_cls2, 'g-o', label='Dice (Class 2)')\n",
    "ax1.plot(epochs_dice, avg_dice_fg, 'k--o', label='Avg Dice (Foregrounds)')\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Dice Score\")\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "# Create a second y-axis for the training loss.\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(epochs_loss, train_loss, 'r-s', linestyle='--', label='Train Loss (In-sample Error)')\n",
    "ax2.set_ylabel(\"Train Loss\")\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "ax2.set_ylim(0, max(train_loss) * 1.1)  # adjust as needed\n",
    "\n",
    "# Combine legends from both axes.\n",
    "lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='best')\n",
    "\n",
    "plt.title(\"Validation Dice Scores and Train Loss per Epoch\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
